{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load packages and set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "import database as db # our script for simpler db integration\n",
    "from config import config # pull sensitive data from .ini files\n",
    "\n",
    "# set data directory\n",
    "data_path = (os.getcwd() + \"/Data/\")\n",
    "\n",
    "# connection to Postgres database\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create tables for database\n",
    "\n",
    "Think about schema design, primary/foreign keys, datatypes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Endpoint tracker\n",
    "\n",
    "Track position ID for each endpoint in API. Enables reading from that position instead of reloading full data each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, \"drop table endpoint_tracker\")\n",
    "db.execute_query(conn, \"create table endpoint_tracker(endpoint_id serial primary key, endpoint_nme varchar(30), next_start int, update_dtm timestamp default current_timestamp)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_values() done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'deals', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157)),\n",
       " (2, 'organizations', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157)),\n",
       " (3, 'persons', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157)),\n",
       " (4, 'products', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157))]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_tracker = pd.DataFrame({\n",
    "    'endpoint_nme': ['deals','organizations','persons','products'],\n",
    "    'next_start': [0, 0, 0, 0]\n",
    "})\n",
    "\n",
    "db.execute_values(conn, product_tracker, 'endpoint_tracker')\n",
    "\n",
    "# initialize db tracker\n",
    "db.execute_query(conn, \"select * from endpoint_tracker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, \"drop table products\")\n",
    "db.execute_query(conn, \"create table products(product_id int primary key, product_nme varchar(50), product_cde varchar(10), product_dsc varchar(100), active_ind boolean, owner_id int, owner_nme varchar(50), insert_dte date, update_dte date, price_id int, price_amt numeric(9,2))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, \"drop table persons\")\n",
    "db.execute_query(conn, \"\"\"\n",
    "create table persons (\n",
    "    persons_id int primary key,\n",
    "    first_nme varchar(100),\n",
    "    last_nme varchar(100),\n",
    "    open_cnt int,\n",
    "    closed_cnt int,\n",
    "    emails_cnt int,\n",
    "    activities_cnt int,\n",
    "    won_cnt int,\n",
    "    lost_cnt int,\n",
    "    active_ind boolean,\n",
    "    update_dte date,\n",
    "    insert_dte date,\n",
    "    last_activity_dte date,\n",
    "    last_inmail_dte date,\n",
    "    last_outmail_dte date,\n",
    "    org_nme varchar(100),\n",
    "    owner_id int,\n",
    "    owner_nme varchar(100),\n",
    "    owner_active_ind boolean,\n",
    "    org_active_ind boolean,\n",
    "    org_id int\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract data from Pipedrive\n",
    "\n",
    "deals\n",
    "\n",
    "orgainzations\n",
    "\n",
    "persons\n",
    "\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(endpoint, start, limit):\n",
    "    \n",
    "    params = config(section='pipedrive')\n",
    "    params.update({'start':start,'limit':limit})\n",
    "    \n",
    "    response = requests.get(params['company_domain'] + endpoint, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        json_msg = response.json()\n",
    "        print('Extraction of {} data from Pipedrive complete.'.format(endpoint))\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "    \n",
    "    data = json_msg['data']\n",
    "    \n",
    "    if json_msg['additional_data']['pagination']['more_items_in_collection']:\n",
    "        next_start = json_msg['additional_data']['pagination']['next_start']\n",
    "    elif data is None:\n",
    "        next_start = start\n",
    "    else:\n",
    "        next_start = len(data)\n",
    "    \n",
    "    return data, next_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def products_to_df(json_data, dtm_to_dte=True):\n",
    "    \n",
    "    # read product data\n",
    "    products = pd.json_normalize(json_data)[['id','name','code','description','active_flag','owner_id.id','owner_id.name','add_time','update_time']]\n",
    "\n",
    "    # rename columns\n",
    "    products.rename(\n",
    "        columns={\n",
    "            'id':'product_id',\n",
    "            'name':'product_nme',\n",
    "            'code':'product_cde',\n",
    "            'description':'product_dsc',\n",
    "            'active_flag':'active_ind',\n",
    "            'owner_id.id':'owner_id',\n",
    "            'owner_id.name':'owner_nme',\n",
    "            'add_time':'insert_dte',\n",
    "            'update_time':'update_dte'\n",
    "        }, inplace=True)\n",
    "\n",
    "    # read individual price data\n",
    "    prices = pd.json_normalize(json_data, 'prices')[['id','price','product_id']]\n",
    "\n",
    "    # rename columns\n",
    "    prices.rename(\n",
    "        columns={\n",
    "            'id':'price_id',\n",
    "            'price':'price_amt'\n",
    "        }, inplace=True\n",
    "    )\n",
    "\n",
    "    # join price data back to product -- unnecessary complexity to keep both\n",
    "    products = products.join(prices.set_index('product_id'), on='product_id')\n",
    "\n",
    "    # convert to timestamps\n",
    "    for col in ['insert_dte','update_dte']:\n",
    "        products[col] = pd.to_datetime(products[col])\n",
    "        # conditionally strip timestamp\n",
    "        if dtm_to_dte:\n",
    "            products[col] = products[col].dt.date\n",
    "    \n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl(endpoint, limit=500):\n",
    "    \n",
    "    if endpoint not in ['products','persons','deals','organizations']:\n",
    "        print('{} is not a valid endpoint. Please try again.'.format(endpoint))\n",
    "        return\n",
    "    \n",
    "    # find last start position\n",
    "    start_pos = db.execute_query(conn, \"select next_start from endpoint_tracker where endpoint_nme = '{endpoint}'\".format(endpoint=endpoint))[0]\n",
    "\n",
    "    # read MAX rows from most recently stored data\n",
    "    json_data, start_pos = get_data(endpoint, start=start_pos, limit=limit)\n",
    "\n",
    "    if json_data is not None:\n",
    "        # increment tracker to new start\n",
    "        db.execute_query(conn, \"update endpoint_tracker set next_start = {pos}, update_dtm = current_timestamp where endpoint_nme = '{endpoint}'\".format(pos=start_pos, endpoint=endpoint))\n",
    "\n",
    "        # convert to df\n",
    "        if endpoint == 'products':\n",
    "            data = products_to_df(json_data)\n",
    "        elif endpoint == 'persons':\n",
    "            data = persons_to_df(json_data)\n",
    "        else:\n",
    "            print('no other workflows defined right now...')\n",
    "\n",
    "        print('Transform complete.')\n",
    "        \n",
    "        # write data to database\n",
    "        db.execute_values(conn, data, endpoint)\n",
    "        \n",
    "        print('Load to database complete.')\n",
    "        \n",
    "    else:\n",
    "        print('No more {} data - tracker at position {}.'.format(endpoint, *start_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction of products data from Pipedrive complete.\n",
      "Transform complete.\n",
      "execute_values() done\n",
      "Load to database complete.\n"
     ]
    }
   ],
   "source": [
    "etl('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'deals', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157)),\n",
       " (2, 'organizations', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157)),\n",
       " (4, 'products', 7, datetime.datetime(2020, 9, 17, 22, 46, 38, 13641)),\n",
       " (3, 'persons', 0, datetime.datetime(2020, 9, 17, 22, 52, 24, 590015))]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, \"select * from endpoint_tracker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'Pro',\n",
       "  'PRO',\n",
       "  None,\n",
       "  True,\n",
       "  7316834,\n",
       "  'Kirk Behrendt',\n",
       "  datetime.date(2018, 12, 7),\n",
       "  datetime.date(2020, 6, 16),\n",
       "  1,\n",
       "  Decimal('3700.00')),\n",
       " (3,\n",
       "  'Inner Circle',\n",
       "  'IC',\n",
       "  None,\n",
       "  True,\n",
       "  7316834,\n",
       "  'Kirk Behrendt',\n",
       "  datetime.date(2019, 2, 5),\n",
       "  datetime.date(2019, 2, 5),\n",
       "  3,\n",
       "  Decimal('0.00')),\n",
       " (4,\n",
       "  'Dental Intel',\n",
       "  'DI',\n",
       "  None,\n",
       "  True,\n",
       "  7316834,\n",
       "  'Kirk Behrendt',\n",
       "  datetime.date(2019, 2, 5),\n",
       "  datetime.date(2019, 2, 5),\n",
       "  4,\n",
       "  Decimal('0.00')),\n",
       " (5,\n",
       "  'Connect',\n",
       "  'CONNECT',\n",
       "  None,\n",
       "  True,\n",
       "  7316834,\n",
       "  'Kirk Behrendt',\n",
       "  datetime.date(2019, 2, 5),\n",
       "  datetime.date(2019, 2, 5),\n",
       "  5,\n",
       "  Decimal('0.00')),\n",
       " (6,\n",
       "  'Academy',\n",
       "  'ACADEMY',\n",
       "  None,\n",
       "  True,\n",
       "  7316834,\n",
       "  'Kirk Behrendt',\n",
       "  datetime.date(2019, 2, 5),\n",
       "  datetime.date(2019, 2, 5),\n",
       "  6,\n",
       "  Decimal('0.00')),\n",
       " (8,\n",
       "  'Practice Assessment - Onsite',\n",
       "  None,\n",
       "  None,\n",
       "  True,\n",
       "  7316834,\n",
       "  'Kirk Behrendt',\n",
       "  datetime.date(2019, 6, 26),\n",
       "  datetime.date(2019, 6, 26),\n",
       "  8,\n",
       "  Decimal('0.00')),\n",
       " (9,\n",
       "  '5964',\n",
       "  None,\n",
       "  None,\n",
       "  True,\n",
       "  7573109,\n",
       "  'Barb James',\n",
       "  datetime.date(2019, 11, 21),\n",
       "  datetime.date(2019, 11, 21),\n",
       "  9,\n",
       "  Decimal('0.00'))]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, \"select * from products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persons_to_df(json_data, dtm_to_dte=True):\n",
    "    \n",
    "    persons = pd.json_normalize(json_data)[['id','first_name','last_name','open_deals_count','closed_deals_count','email_messages_count','activities_count','won_deals_count','lost_deals_count','active_flag','update_time','add_time','last_activity_date','last_incoming_mail_time','last_outgoing_mail_time','org_name','owner_id.id','owner_id.name','owner_id.active_flag','org_id.active_flag','org_id.value']]\n",
    "    \n",
    "    persons.rename(\n",
    "        columns={\n",
    "            'id':'persons_id',\n",
    "            'first_name':'first_nme',\n",
    "            'last_name':'last_nme',\n",
    "            'open_deals_count':'open_cnt',\n",
    "            'closed_deals_count':'closed_cnt',\n",
    "            'email_messages_count':'emails_cnt',\n",
    "            'activities_count':'activities_cnt',\n",
    "            'won_deals_count':'won_cnt',\n",
    "            'lost_deals_count':'lost_cnt',\n",
    "            'active_flag':'active_ind',\n",
    "            'update_time':'update_dte',\n",
    "            'add_time':'insert_dte',\n",
    "            'last_activity_date':'last_activity_dte',\n",
    "            'last_incoming_mail_time':'last_inmail_dte',\n",
    "            'last_outgoing_mail_time':'last_outmail_dte',\n",
    "            'org_name':'org_nme',\n",
    "            'owner_id.id':'owner_id',\n",
    "            'owner_id.name':'owner_nme',\n",
    "            'owner_id.active_flag':'owner_active_ind',\n",
    "            'org_id.active_flag':'org_active_ind',\n",
    "            'org_id.value':'org_id'\n",
    "        }, inplace=True)\n",
    "    \n",
    "    # convert to timestamps\n",
    "    for col in ['update_dte','insert_dte','last_activity_dte','last_inmail_dte','last_outmail_dte']:\n",
    "        persons[col] = pd.to_datetime(persons[col])\n",
    "        persons[col].fillna(pd.to_datetime('1900-01-01'), inplace=True)\n",
    "        # conditionally strip timestamp\n",
    "        if dtm_to_dte:\n",
    "            persons[col] = persons[col].dt.date\n",
    "        \n",
    "    # handle missing values\n",
    "    persons['org_nme'].fillna('', inplace=True)\n",
    "    persons['org_active_ind'].fillna(False, inplace=True)\n",
    "    persons['org_id'].fillna(-1, inplace=True)\n",
    "    \n",
    "    return persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Areas for improvement\n",
    "\n",
    "Error handling on queries -- maybe return a specific number (-1) on failed query. Before moving on, check for -1.\n",
    "\n",
    "If we encounter -1 returned at ANY TIME, we should immediately break out of the ETL function.\n",
    "\n",
    "Should not increment position in endpoint_tracker if query or data pull is unsuccessful. Maybe push the increment later in the ETL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction of persons data from Pipedrive complete.\n",
      "Transform complete.\n",
      "Error: duplicate key value violates unique constraint \"persons_pkey\"\n",
      "DETAIL:  Key (persons_id)=(359) already exists.\n",
      "\n",
      "Load to database complete.\n"
     ]
    }
   ],
   "source": [
    "etl('persons',limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate until we have all data\n",
    "while True:\n",
    "    etl('persons') # returns False if part of workflow fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16187,)]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, 'select max(persons_id) from persons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16169,\n",
       "  'kim',\n",
       "  'lien hoang',\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  True,\n",
       "  datetime.date(2020, 9, 17),\n",
       "  datetime.date(2020, 9, 17),\n",
       "  datetime.date(1900, 1, 1),\n",
       "  datetime.date(2020, 4, 24),\n",
       "  datetime.date(2020, 4, 24),\n",
       "  '',\n",
       "  7316834,\n",
       "  'Kirk Behrendt',\n",
       "  True,\n",
       "  False,\n",
       "  -1)]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, 'select * from persons where persons_id = 16169')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'deals', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157)),\n",
       " (2, 'organizations', 0, datetime.datetime(2020, 9, 17, 22, 46, 21, 86157)),\n",
       " (4, 'products', 7, datetime.datetime(2020, 9, 17, 22, 46, 38, 13641)),\n",
       " (3, 'persons', 14682, datetime.datetime(2020, 9, 17, 22, 59, 4, 459471))]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(conn, 'select * from endpoint_tracker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved deals data from Pipedrive\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stage_id</th>\n",
       "      <th>title</th>\n",
       "      <th>value</th>\n",
       "      <th>currency</th>\n",
       "      <th>add_time</th>\n",
       "      <th>update_time</th>\n",
       "      <th>stage_change_time</th>\n",
       "      <th>active</th>\n",
       "      <th>deleted</th>\n",
       "      <th>...</th>\n",
       "      <th>e95d6b75fe35d641090f38583a71c3f782c0bb4e.email</th>\n",
       "      <th>e95d6b75fe35d641090f38583a71c3f782c0bb4e.phone</th>\n",
       "      <th>e95d6b75fe35d641090f38583a71c3f782c0bb4e.value</th>\n",
       "      <th>a7357ae350bb916a359a580ce5847b896b79cc97.name</th>\n",
       "      <th>a7357ae350bb916a359a580ce5847b896b79cc97.people_count</th>\n",
       "      <th>a7357ae350bb916a359a580ce5847b896b79cc97.owner_id</th>\n",
       "      <th>a7357ae350bb916a359a580ce5847b896b79cc97.address</th>\n",
       "      <th>a7357ae350bb916a359a580ce5847b896b79cc97.active_flag</th>\n",
       "      <th>a7357ae350bb916a359a580ce5847b896b79cc97.cc_email</th>\n",
       "      <th>a7357ae350bb916a359a580ce5847b896b79cc97.value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13040</td>\n",
       "      <td>65</td>\n",
       "      <td>Discovery Study Club Lecture</td>\n",
       "      <td>7900</td>\n",
       "      <td>USD</td>\n",
       "      <td>2019-03-29 02:29:30</td>\n",
       "      <td>2020-09-02 17:29:42</td>\n",
       "      <td>2019-05-31 18:11:53</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'label': 'work', 'value': 'dr.mark@realteeth...</td>\n",
       "      <td>[{'label': 'mobile', 'value': '412-996-2023', ...</td>\n",
       "      <td>14908</td>\n",
       "      <td>Discovery Study Club</td>\n",
       "      <td>2</td>\n",
       "      <td>7573109</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>actdental-c8c401@pipedrivemail.com</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  stage_id                         title  value currency  \\\n",
       "0  13040        65  Discovery Study Club Lecture   7900      USD   \n",
       "\n",
       "              add_time          update_time    stage_change_time  active  \\\n",
       "0  2019-03-29 02:29:30  2020-09-02 17:29:42  2019-05-31 18:11:53    True   \n",
       "\n",
       "   deleted  ...     e95d6b75fe35d641090f38583a71c3f782c0bb4e.email  \\\n",
       "0    False  ...  [{'label': 'work', 'value': 'dr.mark@realteeth...   \n",
       "\n",
       "      e95d6b75fe35d641090f38583a71c3f782c0bb4e.phone  \\\n",
       "0  [{'label': 'mobile', 'value': '412-996-2023', ...   \n",
       "\n",
       "  e95d6b75fe35d641090f38583a71c3f782c0bb4e.value  \\\n",
       "0                                          14908   \n",
       "\n",
       "  a7357ae350bb916a359a580ce5847b896b79cc97.name  \\\n",
       "0                          Discovery Study Club   \n",
       "\n",
       "   a7357ae350bb916a359a580ce5847b896b79cc97.people_count  \\\n",
       "0                                                  2       \n",
       "\n",
       "   a7357ae350bb916a359a580ce5847b896b79cc97.owner_id  \\\n",
       "0                                            7573109   \n",
       "\n",
       "  a7357ae350bb916a359a580ce5847b896b79cc97.address  \\\n",
       "0                                             None   \n",
       "\n",
       "  a7357ae350bb916a359a580ce5847b896b79cc97.active_flag  \\\n",
       "0                                               True     \n",
       "\n",
       "  a7357ae350bb916a359a580ce5847b896b79cc97.cc_email  \\\n",
       "0                actdental-c8c401@pipedrivemail.com   \n",
       "\n",
       "  a7357ae350bb916a359a580ce5847b896b79cc97.value  \n",
       "0                                            459  \n",
       "\n",
       "[1 rows x 161 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deals, deals_start = get_data('deals',start=0,limit=1)\n",
    "pd.json_normalize(deals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
